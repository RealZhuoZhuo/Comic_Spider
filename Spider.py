import aiofiles
import httpx
from lxml import etree
import asyncio
import os
from concurrent.futures import ProcessPoolExecutor
base_url = "xx"
import time
path = "xx"
sem = asyncio.Semaphore(50)
#ä¸‹è½½æ¯ä¸€ç”»çš„æ¼«ç”»
async def download_comic(chapter, title):
    try:
         async with sem:
            async with httpx.AsyncClient() as client:
                res = await client.get(base_url+chapter,timeout=1000)
                res.raise_for_status()
                html = etree.HTML(res.text)
                src = html.xpath("//div[@id='content']//a/img/@src")[0]
                name = src.split('/')[-1]
                img = await client.get(src,timeout=1000)
                img.raise_for_status()
                async with aiofiles.open(f"./æ¼«ç”»/{title[0]+title[1]}/{name}","wb") as f:
                    await f.write(img.content)
                print(f"âœ”ï¸  æˆåŠŸä¿å­˜{title[0]+title[1]}/{name}")
    except Exception as e:
        print(f"ğŸš«  ä¸‹è½½{title}å¤±è´¥ï¼š{str(e)}")
#è·å–æ¼«ç”»ç›®å½•
async def fetch_catalog(url):
    try:
        async with httpx.AsyncClient() as client:
            res = await client.get(url,timeout=1000)
            res.raise_for_status()
            html = etree.HTML(res.text)
            chapters = html.xpath("//div[@class='thumb-container']/a[@class='gallerythumb']/@href")
            if not chapters:
                print(f"ğŸš«  æ— æœ‰æ•ˆç« èŠ‚ {url}")
                return
            title = html.xpath("//div[@id='info']/h2[@class='title']//text()")
            if not title:
                print(f"ğŸš«  æ— æœ‰æ•ˆåå­— {url}")
                return
            os.mkdir(f'./æ¼«ç”»/{title[0]+title[1]}')
            tasks = [download_comic(chapter,title) for chapter in chapters]
            await asyncio.gather(*tasks)
    except Exception as e:
        print(f"ğŸš«  å¤„ç†{url}å¤±è´¥: {str(e)}")
#è·å–æ¼«ç”»ä»¬
def start(url):
    asyncio.run(fetch_catalog(base_url+url))

async def main():
    async with httpx.AsyncClient() as client:
        res =await client.get(path,timeout=1000)
        html = etree.HTML(res.text)
        lists = html.xpath("//div[@class='container index-container']//div[@class='gallery']/a/@href")
        loop = asyncio.get_running_loop()
        with ProcessPoolExecutor(max_workers=4) as pool:
            tasks = [
                loop.run_in_executor(pool,start,list)
                for list in lists
            ]
            await asyncio.gather(*tasks)
        
   
if __name__=="__main__":
    os.mkdir("æ¼«ç”»")
    t1=time.time()
    asyncio.run(main())
    print(f"æ—¶é—´ä¸º{time.time()-t1}\n")